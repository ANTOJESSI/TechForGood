#Code 

# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lacfSBrIlWsLnp7_RLsVTtMGHRHS5eke
"""

import pandas as pd
import zipfile

# Path to the zip file
zip_file_path = '/content/Plant_1_Generation_Data.csv.zip'

# Extract and read the CSV file from the zip
with zipfile.ZipFile(zip_file_path, 'r') as z:
    z.extractall('/content/')

# Load the CSV file into a pandas DataFrame
file_path = '/content/Plant_1_Generation_Data.csv'
data = pd.read_csv(file_path)

# Display the first few rows to understand the structure of the dataset
print(data.head())

# Check for missing values
print(data.isnull().sum())

# Get a statistical summary of the data
print(data.describe())

# Get an overview of data types in the DataFrame
print(data.info())

import pandas as pd
import matplotlib.pyplot as plt

# Load the data
data = pd.read_csv('/content/Plant_1_Generation_Data.csv.zip')

# Convert 'DATE_TIME' to a datetime format
data['DATE_TIME'] = pd.to_datetime(data['DATE_TIME'])

# Plot energy generation over time (using 'DC_POWER')
plt.figure(figsize=(10,6))
plt.plot(data['DATE_TIME'], data['DC_POWER'], label='DC Power')
plt.title('Energy Generation Over Time')
plt.xlabel('Date and Time')
plt.ylabel('DC Power (kW)')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.legend()
plt.tight_layout()  # Adjusts plot layout for readability
plt.show()

# Optional: You can also plot AC power if needed
plt.figure(figsize=(10,6))
plt.plot(data['DATE_TIME'], data['AC_POWER'], label='AC Power', color='orange')
plt.title('AC Power Generation Over Time')
plt.xlabel('Date and Time')
plt.ylabel('AC Power (kW)')
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.show()



correlation = data[['DC_POWER', 'AC_POWER']].corr()
print(correlation)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Load the dataset
data = pd.read_csv('/content/Plant_1_Generation_Data.csv.zip')

# Convert 'DATE_TIME' to datetime
data['DATE_TIME'] = pd.to_datetime(data['DATE_TIME'])

# Sort data by date time (important for time series)
data = data.sort_values(by='DATE_TIME')

# Extract useful features from 'DATE_TIME' (Optional)
data['Hour'] = data['DATE_TIME'].dt.hour
data['Day'] = data['DATE_TIME'].dt.day
data['Month'] = data['DATE_TIME'].dt.month

# Select features (we use past values for prediction)
features = ['Hour', 'Day', 'Month', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD']
target = 'DC_POWER'

# Handle missing values (if any)
data = data.dropna()

# Scaling the data (important for time series prediction)
scaler = MinMaxScaler()
data[features] = scaler.fit_transform(data[features])

# Split the data into training and testing sets
X = data[features]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# Example: Predict future DC Power
future_predictions = model.predict(X_test)





import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM

# Reshape the data for LSTM (samples, timesteps, features)
X_train_reshaped = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))
X_test_reshaped = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))

# Build the LSTM model
lstm_model = Sequential()
lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(1, X_train.shape[1])))
lstm_model.add(LSTM(units=50, return_sequences=False))
lstm_model.add(Dense(units=1))

# Compile the model
lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
lstm_model.fit(X_train_reshaped, y_train, batch_size=32, epochs=10)

# Predict on the test set
lstm_predictions = lstm_model.predict(X_test_reshaped)

# Evaluate the LSTM model
lstm_mse = mean_squared_error(y_test, lstm_predictions)
print(f'LSTM Mean Squared Error: {lstm_mse}')

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Input

# Reshape the data for LSTM (samples, timesteps, features)
X_train_reshaped = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))
X_test_reshaped = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))

# Build the LSTM model
lstm_model = Sequential()

# Add the Input layer to avoid the warning
lstm_model.add(Input(shape=(1, X_train.shape[1])))

# Add LSTM layers
lstm_model.add(LSTM(units=50, return_sequences=True))
lstm_model.add(LSTM(units=50, return_sequences=False))

# Add Dense layer for final prediction
lstm_model.add(Dense(units=1))

# Compile the model
lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
lstm_model.fit(X_train_reshaped, y_train, batch_size=32, epochs=10)

# Predict on the test set
lstm_predictions = lstm_model.predict(X_test_reshaped)

# Evaluate the LSTM model
lstm_mse = mean_squared_error(y_test, lstm_predictions)
print(f'LSTM Mean Squared Error: {lstm_mse}')

# FINAL OUTPUTS


Mean Squared Error: 121.23986823773522



Epoch 1/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 10s 3ms/step - loss: 26884068.0000
Epoch 2/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - loss: 26519544.0000
Epoch 3/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 25831444.0000
Epoch 4/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 25753988.0000
Epoch 5/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - loss: 25355072.0000
Epoch 6/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 9s 3ms/step - loss: 25117218.0000
Epoch 7/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - loss: 24719496.0000
Epoch 8/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 24337110.0000
Epoch 9/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - loss: 23742852.0000
Epoch 10/10
1720/1720 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 23426134.0000
430/430 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step
LSTM Mean Squared Error: 18874133.347266633
